{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Activation,Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load valence data\n",
    "dataset=pd.read_csv('E:/SLIIT/Research/VA/valence-arousal-recognition-master/valence-arousal-recognition-master/AffectDataFiles/AffectTrain.csv').values\n",
    "\n",
    "data=dataset[:,4]\n",
    "target=dataset[:,2].reshape(-1,1)\n",
    "\n",
    "print(data[0],target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "\n",
    "# sns.set(style='whitegrid',palette=\"deep\",rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform data\n",
    "\n",
    "scaler=MinMaxScaler()\n",
    "target=scaler.fit_transform(target)\n",
    "print(target[0])\n",
    "\n",
    "joblib.dump(scaler, 'val-scaler.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model \n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(256,(3,3),input_shape=(48,48,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(200,activation='relu'))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='adam',metrics=['mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "img_size=48\n",
    "\n",
    "def batcher(data,target):\n",
    "    \n",
    "    global img_size,batch_size\n",
    "    \n",
    "    def preprocess(img_name):\n",
    "        img=cv2.imread(os.path.abspath(img_name))\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        img=cv2.resize(img,(img_size,img_size))/255\n",
    "        \n",
    "        return img.reshape(img_size,img_size,1)\n",
    "\n",
    "    while(True):\n",
    "        \n",
    "        data_new=[]\n",
    "        target_new=[]\n",
    "        \n",
    "     \n",
    "        inds=np.random.randint(0,len(data),batch_size)\n",
    "\n",
    "        for index in inds:\n",
    "\n",
    "            data_new.append(preprocess(data[index]))\n",
    "            target_new.append(target[index])\n",
    "        \n",
    "\n",
    "        yield np.array(data_new),np.array(target_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_batcher(data,target):\n",
    "    \n",
    "    global img_size,batch_size\n",
    "    \n",
    "    data_new=[]\n",
    "    target_new=[]\n",
    "    \n",
    "    def preprocess(img_name):\n",
    "\n",
    "        img=cv2.imread(os.path.abspath(img_name))\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        img=cv2.resize(img,(img_size,img_size))/255\n",
    "        \n",
    "        return img.reshape(img_size,img_size,1)\n",
    "\n",
    "    for index in range(len(data)):\n",
    "\n",
    "        data_new.append(preprocess(data[index]))\n",
    "        target_new.append(target[index])\n",
    "        \n",
    "    return np.array(data_new),np.array(target_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset\n",
    "train_data,test_data,train_target,test_target=train_test_split(data,target,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(train_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train the model\n",
    "batch_size=8\n",
    "\n",
    "checkpoint=ModelCheckpoint(filepath='models_va-{epoch:02d}',monitor='val_loss',mode='min',save_best_only=True)\n",
    "\n",
    "history = model.fit(batcher(train_data,train_target),epochs=400,validation_data=batcher(test_data,test_target),\n",
    "          batch_size=batch_size,\n",
    "          steps_per_epoch=len(train_data)//batch_size,validation_steps=len(test_data)//batch_size,callbacks=[checkpoint])\n",
    "\n",
    "model.save_weights(\"affect_valence.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving valence model to file\n",
    "model_json = model.to_json()\n",
    "\n",
    "json_file = open(\"affect_valence.json\", \"w\")\n",
    "json_file.write(model_json)\n",
    "json_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Create chart\n",
    "plt.plot(history.history['loss'],'b')\n",
    "plt.plot(history.history['val_loss'],'r')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch #')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create chart\n",
    "\n",
    "plt.plot(history.history['mae'],'b', label=\"mae\")\n",
    "plt.plot(history.history['val_mae'],'r',label=\"validate mae\")\n",
    "plt.legend()\n",
    "plt.xlabel('epoch #')\n",
    "plt.ylabel('mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vald_data,val_target=test_batcher(test_data,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "#Prediction\n",
    "pred = model.predict(vald_data)\n",
    "\n",
    "score = metrics.mean_squared_error(pred, val_target)\n",
    "print(\"final score (MSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#r2 score\n",
    "\n",
    "r2=r2_score(val_target.flatten(),pred.flatten())\n",
    "print('r2:',r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arousal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "dataset=pd.read_csv('E:/SLIIT/Research/VA/valence-arousal-recognition-master/valence-arousal-recognition-master/AffectDataFiles/AffectTrain.csv').values\n",
    "\n",
    "data_arousal=dataset[:,4]\n",
    "target_arousal=dataset[:,1].reshape(-1,1)\n",
    "\n",
    "print(data_arousal[1],target_arousal[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform data\n",
    "scaler=MinMaxScaler()\n",
    "target=scaler.fit_transform(target_arousal)\n",
    "print(target_arousal[1])\n",
    "joblib.dump(scaler, 'arl-scaler.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(256,(3,3),input_shape=(48,48,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(200,activation='relu'))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='adam',metrics=['mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "img_size=48\n",
    "\n",
    "def batcher(data_arousal,target_arousal):\n",
    "    \n",
    "    global img_size,batch_size\n",
    "    \n",
    "    def preprocess(img_name):\n",
    "        img=cv2.imread(os.path.abspath(img_name))\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        img=cv2.resize(img,(img_size,img_size))/255\n",
    "        \n",
    "        return img.reshape(img_size,img_size,1)\n",
    "\n",
    "    while(True):\n",
    "        \n",
    "        data_new=[]\n",
    "        target_new=[]\n",
    "        \n",
    "     \n",
    "        inds=np.random.randint(0,len(data),batch_size)\n",
    "\n",
    "        for index in inds:\n",
    "\n",
    "            data_new.append(preprocess(data[index]))\n",
    "            target_new.append(target[index])\n",
    "        \n",
    "\n",
    "        yield np.array(data_new),np.array(target_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_batcher(data_arousal,target_arousal):\n",
    "    \n",
    "    global img_size,batch_size\n",
    "    \n",
    "    data_new=[]\n",
    "    target_new=[]\n",
    "    \n",
    "    def preprocess(img_name):\n",
    "\n",
    "        img=cv2.imread(os.path.abspath(img_name))\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        img=cv2.resize(img,(img_size,img_size))/255\n",
    "        \n",
    "        return img.reshape(img_size,img_size,1)\n",
    "\n",
    "    for index in range(len(data)):\n",
    "\n",
    "        data_new.append(preprocess(data[index]))\n",
    "        target_new.append(target[index])\n",
    "        \n",
    "    return np.array(data_new),np.array(target_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "train_data_ar,test_data_ar,train_target_ar,test_target_ar=train_test_split(data_arousal,target_arousal,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "\n",
    "batch_size=8\n",
    "\n",
    "checkpoint=ModelCheckpoint(filepath='models_ar-{epoch:02d}',monitor='val_loss',mode='min',save_best_only=True)\n",
    "\n",
    "history = model.fit(batcher(train_data_ar,train_target_ar),epochs=300,validation_data=batcher(test_data_ar,test_target_ar),\n",
    "          batch_size=batch_size,\n",
    "          steps_per_epoch=len(train_data_ar)//batch_size,validation_steps=len(test_data_ar)//batch_size,callbacks=[checkpoint])\n",
    "\n",
    "model.save_weights(\"arousal_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving arousal model to file\n",
    "model_json = model.to_json()\n",
    "\n",
    "json_file = open(\"arousal_model.json\", \"w\")\n",
    "json_file.write(model_json)\n",
    "json_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create chart\n",
    "\n",
    "plt.plot(history.history['loss'],'b',label='train loss')\n",
    "plt.plot(history.history['val_loss'],'r',label='val loss')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch #')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create chart\n",
    "\n",
    "plt.plot(history.history['mae'],'b', label=\"mae\")\n",
    "plt.plot(history.history['val_mae'],'r',label=\"validate mae\")\n",
    "plt.legend()\n",
    "plt.xlabel('epoch #')\n",
    "plt.ylabel('mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the valence model using test data\n",
    "\n",
    "vald_data_va,val_target_va=test_batcher(test_data_va,test_target_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the arousal model using test data\n",
    "\n",
    "vald_data_ar,val_target_ar=test_batcher(test_data_ar,test_target_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "\n",
    "pred_ar = model.predict(vald_data_ar)\n",
    "\n",
    "score_ar = metrics.mean_squared_error(pred_ar, val_target_ar)\n",
    "print(\"final score (MSE): {}\".format(score_ar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r2 score\n",
    "\n",
    "r2_ar=r2_score(val_target_ar.flatten(),pred_ar.flatten())\n",
    "print('r2:',r2_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
