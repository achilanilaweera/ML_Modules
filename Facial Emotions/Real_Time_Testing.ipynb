{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5648c766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from time import time, sleep\n",
    "import joblib\n",
    "# from firebase import firebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71738e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pre-trained models to recognize face area and landmarks in the face \n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "landmark_detector=dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fd86f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import trained models\n",
    "emotion_model = load_model('models-44')\n",
    "ear_model=load_model('EAR.model')\n",
    "arousal_model = load_model('models_ar-296')\n",
    "valence_model = load_model('models_va-229')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66048541",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_scaler=joblib.load('arl-scaler.sav')\n",
    "vl_scaler=joblib.load('val-scaler.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1297d1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_labels = ['angry','happy', 'sad', 'surprise', 'neutral']\n",
    "ear_dict={0:'alert',1: 'drowsy'}\n",
    "\n",
    "face_detector=dlib.get_frontal_face_detector()\n",
    "\n",
    "window_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36795d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Array initialization\n",
    "timeList = []\n",
    "dateList = []\n",
    "predEmotions = []\n",
    "predSleepiness = []\n",
    "predVal = []\n",
    "predAr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "984e3c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentDate_1 = date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3262ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create CSV file\n",
    "def FerDataFrame():\n",
    "    dictData = {'Date':dateList, 'Time': timeList, 'Emotion Category': predEmotions, 'Sleepiness Stage':predSleepiness, 'Valence':predVal,'Arousal':predAr }\n",
    "    \n",
    "    dfData = pd.DataFrame(dictData)\n",
    "    print(dfData)\n",
    "\n",
    "    dfData.to_csv(str(currentDate_1) + '_FERData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8de30241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sleepinessTimeFrame():\n",
    "#     dictsleepiness = {'Date':dateList,'Time':timeList, 'Sleepiness Stage': predSleepiness}\n",
    "#     dfSleepiness = pd.DataFrame(dictsleepiness)\n",
    "#     print(dfSleepiness)\n",
    "# #     firebase1 = firebase.FirebaseApplication('https://cigapp-d83d9-default-rtdb.asia-southeast1.firebasedatabase.app/', None)\n",
    "# #     result = firebase1.post('Parent/-Ml5UkMGSy1hCModh2Fs/Children/-Ml5V5GB9L1RvGvp0Bf8/sleepiness/', dictsleepiness)\n",
    "#     dfSleepiness.to_csv(str(currentDate_1) + '_Sleepiness.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a59f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realtime emotion detection code\n",
    "def realtimeDetection():\n",
    "    \n",
    "    #Initialization\n",
    "    test_data=[]\n",
    "    ar_vals=[]\n",
    "    vl_vals=[]\n",
    "    count=0\n",
    "    sleepLabel='None'\n",
    "    bestEmotion='None'\n",
    "    bestAr=0\n",
    "    bestVl=0\n",
    "    currentTime = 0\n",
    "    emotionList = []\n",
    "\n",
    "    start_now = datetime.now()\n",
    "    start = start_now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "    cap=cv2.VideoCapture(0)\n",
    "    while(True):\n",
    "        ret,img=cap.read()\n",
    "\n",
    "        if(ret==False):\n",
    "            break\n",
    "        img=cv2.resize(img,(0,0),fx=0.5,fy=0.5)\n",
    "        gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        faces=face_detector(gray)\n",
    "\n",
    "        for face in faces:\n",
    "\n",
    "            x1=face.left()\n",
    "            y1=face.top()\n",
    "            x2=face.right()\n",
    "            y2=face.bottom()\n",
    "\n",
    "            cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "\n",
    "            roi_gray = gray[y1:y2,x1:x2]\n",
    "            \n",
    "            test_img=cv2.resize(roi_gray,(48,48))/255\n",
    "            \n",
    "            roi_gray = cv2.resize(roi_gray,(100,100),interpolation=cv2.INTER_AREA)\n",
    "            roi = roi_gray.astype('float')/255.0\n",
    "            roi = img_to_array(roi)\n",
    "            roi = np.expand_dims(roi,axis=0)\n",
    "\n",
    "            preds = emotion_model.predict(roi)[0]\n",
    "            expLabel=emotion_labels[np.argmax(preds)] \n",
    "            emotionList.append(expLabel)   \n",
    "            \n",
    "            test_img=test_img.reshape(1,48,48,1)\n",
    "            ar_result=arousal_model.predict(test_img)\n",
    "            ar_result=ar_scaler.inverse_transform(ar_result)[0][0]\n",
    "            ar_vals.append(ar_result)\n",
    "            \n",
    "            vl_result=valence_model.predict(test_img)\n",
    "            vl_result=vl_scaler.inverse_transform(vl_result)[0][0]\n",
    "            vl_vals.append(vl_result)\n",
    "            \n",
    "            points=landmark_detector(gray,face)\n",
    "\n",
    "            points=face_utils.shape_to_np(points)\n",
    "\n",
    "            for i,p in enumerate(points):\n",
    "\n",
    "                cen=(p[0],p[1])\n",
    "                cv2.circle(img,cen,2,(0,255,0),-1)\n",
    "\n",
    "            cv2.line(img,tuple(points[37]),tuple(points[41]),(0,0,255),2)\n",
    "            cv2.line(img,tuple(points[44]),tuple(points[46]),(0,0,255),2)\n",
    "\n",
    "            p1=points[36][0]\n",
    "            p2=points[37][1]\n",
    "            p3=points[38][1]\n",
    "            p4=points[39][0]\n",
    "            p5=points[40][1]\n",
    "            p6=points[41][1]\n",
    "\n",
    "            eye_ratio=(abs(p2-p6)+abs(p3-p5))/abs(p1-p4)\n",
    "            test_data.append(eye_ratio)\n",
    "            count=count+1\n",
    "\n",
    "            if(count==window_size):\n",
    "\n",
    "                test_data=np.array(test_data)\n",
    "                test_data=test_data.reshape(1,test_data.shape[0],1)\n",
    "                result=ear_model.predict(test_data)\n",
    "                label=np.argmax(result,axis=1)[0]\n",
    "               \n",
    "                sleepLabel=ear_dict[label]\n",
    "                bestEmotion=max(emotionList,key=emotionList.count)\n",
    "                bestAr=round(sum(ar_vals)/len(ar_vals),2)\n",
    "                bestVl=round(sum(vl_vals)/len(vl_vals),2)\n",
    "\n",
    "                now = datetime.now()\n",
    "\n",
    "                currentTime = now.strftime(\"%H:%M:%S\")\n",
    "                currentDate = date.today()\n",
    "    \n",
    "                dateList.append(currentDate)\n",
    "                timeList.append(currentTime)       \n",
    "                predEmotions.append(bestEmotion)\n",
    "                predSleepiness.append(sleepLabel)\n",
    "                predVal.append(bestVl)\n",
    "                predAr.append(bestAr)\n",
    "         \n",
    "                count=0\n",
    "                test_data=[]\n",
    "                emotionList=[] \n",
    "                ar_vals=[]\n",
    "                vl_vals=[]\n",
    "                \n",
    "        FerDataFrame()\n",
    "        cv2.putText(img,sleepLabel,(10,50),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,255,255),2) \n",
    "        cv2.putText(img,bestEmotion,(10,100),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,255,0),3)\n",
    "        cv2.putText(img,'AR:'+str(bestAr),(10,150),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,255,0),3) \n",
    "        cv2.putText(img,'VL:'+str(bestVl),(10,200),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,255,0),3) \n",
    "           \n",
    "        cv2.imshow('LIVE',img)\n",
    "        \n",
    "        k=cv2.waitKey(1)\n",
    "        if(k==27):\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a5d1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Schedule to run everyday at 12am\n",
    "import schedule\n",
    "\n",
    "schedule.every().day.at(\"00:00\").do(realtimeDetection())\n",
    "\n",
    "while 1:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fcfeec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
